{
  "metadata": {
    "name": "Business",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "1. Identify the 20 most common merchants in the U.S."
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\ndf \u003d spark.table(\"business\")\r\n\r\nresult \u003d df.groupBy(\"name\") \\\r\n           .count() \\\r\n           .withColumnRenamed(\"count\", \"name_count\") \\\r\n           .withColumnRenamed(\"name\", \"Name\") \\\r\n           .withColumnRenamed(\"name_count\", \"Number of Businesses\") \\\r\n           .orderBy(\"Number of Businesses\", ascending\u003dFalse) \\\r\n           .limit(20)\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "2. Identify the top 10 cities with the most merchants in the U.S."
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\ndf \u003d spark.table(\"business\")\r\n\r\nresult \u003d df.groupBy(\"city\") \\\r\n           .count() \\\r\n           .withColumnRenamed(\"count\", \"business_count\") \\\r\n           .withColumnRenamed(\"city\", \"City\") \\\r\n           .withColumnRenamed(\"business_count\", \"Number of Businesses\") \\\r\n           .orderBy(\"Number of Businesses\", ascending\u003dFalse) \\\r\n           .limit(10)\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "3. Identify the top 5 states with the most merchants in the U.S."
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\ndf \u003d spark.table(\"business\")\r\n\r\nresult \u003d df.groupBy(\"state\") \\\r\n           .count() \\\r\n           .withColumnRenamed(\"count\", \"business_count\") \\\r\n           .withColumnRenamed(\"state\", \"State\") \\\r\n           .withColumnRenamed(\"business_count\", \"Number of Businesses\") \\\r\n           .orderBy(\"Number of Businesses\", ascending\u003dFalse) \\\r\n           .limit(5)\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "4. Identify the 20 most common merchants in the U.S. and display their average ratings."
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nbusiness_df \u003d spark.table(\"business\")\r\n\r\nresult \u003d business_df \\\r\n         .groupBy(\"name\") \\\r\n         .agg({\"stars\": \"avg\", \"name\": \"count\"}) \\\r\n         .withColumnRenamed(\"avg(stars)\", \"Average Rating\") \\\r\n         .withColumnRenamed(\"count(name)\", \"name_count\") \\\r\n         .orderBy(\"name_count\", ascending\u003dFalse) \\\r\n         .select(\"name\", \"Average Rating\") \\\r\n         .withColumnRenamed(\"name\", \"Business Name\") \\\r\n         .limit(20)\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "5. Identify the top 10 cities with the highest ratings."
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nbusiness_df \u003d spark.table(\"business\")\r\n\r\nresult \u003d business_df \\\r\n         .groupBy(\"city\") \\\r\n         .agg({\"stars\": \"avg\"}) \\\r\n         .withColumnRenamed(\"avg(stars)\", \"Average Rating\") \\\r\n         .orderBy(\"Average Rating\", ascending\u003dFalse) \\\r\n         .selectExpr(\"city as City\", \"`Average Rating`\") \\\r\n         .limit(10)\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "6. Count the number of different categories."
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nbusiness_df \u003d spark.table(\"business\")\r\n\r\nbusiness_df_filtered \u003d business_df.filter(business_df.categories.isNotNull())\r\n\r\ncategories_exploded \u003d business_df_filtered.selectExpr(\"explode(split(categories, \u0027,\u0027)) as category\")\r\n\r\nresult \u003d categories_exploded.selectExpr(\"trim(category) as category\") \\\r\n                           .distinct() \\\r\n                           .agg({\"*\": \"count\"}) \\\r\n                           .withColumnRenamed(\"count(1)\", \"The Number of Different Categories\")\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "7. Identify the top 10 most frequent categories and their count."
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nbusiness_df \u003d spark.table(\"business\")\r\n\r\nresult \u003d business_df \\\r\n    .filter(business_df.categories.isNotNull()) \\\r\n    .selectExpr(\"explode(split(categories, \u0027,\u0027)) as category\") \\\r\n    .selectExpr(\"trim(category) as category\") \\\r\n    .groupBy(\"category\") \\\r\n    .count() \\\r\n    .withColumnRenamed(\"count\", \"Category Count\") \\\r\n    .withColumnRenamed(\"category\", \"Category\") \\\r\n    .orderBy(\"Category Count\", ascending\u003dFalse) \\\r\n    .limit(10)\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "8. Identify the top 20 merchants that received the most five-star reviews. "
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nreview_df \u003d spark.table(\"review\")\r\nbusiness_df \u003d spark.table(\"business\")\r\n\r\nresult \u003d review_df \\\r\n    .filter(review_df.rev_stars \u003d\u003d 5) \\\r\n    .groupBy(\"rev_business_id\") \\\r\n    .count() \\\r\n    .withColumnRenamed(\"count\", \"Five-Star Reviews\") \\\r\n    .join(business_df, review_df.rev_business_id \u003d\u003d business_df.business_id) \\\r\n    .select(\"name\", \"Five-Star Reviews\") \\\r\n    .withColumnRenamed(\"name\", \"Business Name\") \\\r\n    .orderBy(\"Five-Star Reviews\", ascending\u003dFalse) \\\r\n    .limit(20)\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "9. Count the number of restaurant types (Chinese, American, Mexican)."
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nbusiness_df \u003d spark.table(\"business\")\r\n\r\nresult \u003d business_df \\\r\n    .filter(business_df.categories.like(\"%Restaurants%\")) \\\r\n    .selectExpr(\r\n        \"CASE \" +\r\n        \"  WHEN categories LIKE \u0027%American%\u0027 THEN \u0027American\u0027 \" +\r\n        \"  WHEN categories LIKE \u0027%Mexican%\u0027 THEN \u0027Mexican\u0027 \" +\r\n        \"  WHEN categories LIKE \u0027%Chinese%\u0027 THEN \u0027Chinese\u0027 \" +\r\n        \"  ELSE \u0027Other\u0027 \" +\r\n        \"END AS cuisine_type\"\r\n    ) \\\r\n    .groupBy(\"cuisine_type\") \\\r\n    .count() \\\r\n    .withColumnRenamed(\"count\", \"restaurant_count\") \\\r\n    .withColumnRenamed(\"cuisine_type\", \"Cuisine Type\") \\\r\n    .withColumnRenamed(\"restaurant_count\", \"Restaurant Count\") \\\r\n    .orderBy(\"Restaurant Count\", ascending\u003dFalse)\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "10. Count the number of reviews for each restaurant type (Chinese, American, Mexican)."
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nbusiness_df \u003d spark.table(\"business\")\r\nreview_df \u003d spark.table(\"review\")\r\n\r\nresult \u003d business_df \\\r\n    .filter(business_df.categories.like(\"%Restaurants%\")) \\\r\n    .join(review_df, business_df.business_id \u003d\u003d review_df.rev_business_id) \\\r\n    .selectExpr(\r\n        \"CASE \" +\r\n        \"  WHEN categories LIKE \u0027%American%\u0027 THEN \u0027American\u0027 \" +\r\n        \"  WHEN categories LIKE \u0027%Mexican%\u0027 THEN \u0027Mexican\u0027 \" +\r\n        \"  WHEN categories LIKE \u0027%Chinese%\u0027 THEN \u0027Chinese\u0027 \" +\r\n        \"  ELSE \u0027Other\u0027 \" +\r\n        \"END AS cuisine_type\"\r\n    ) \\\r\n    .groupBy(\"cuisine_type\") \\\r\n    .count() \\\r\n    .withColumnRenamed(\"count\", \"review_count\") \\\r\n    .withColumnRenamed(\"cuisine_type\", \"Cuisine Type\") \\\r\n    .withColumnRenamed(\"review_count\", \"Review Count\") \\\r\n    .orderBy(\"Review Count\", ascending\u003dFalse)\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "11. Analyze the rating distribution for different restaurant types (Chinese, American, Mexican)."
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nbusiness_df \u003d spark.table(\"business\")\r\nreview_df \u003d spark.table(\"review\")\r\n\r\nresult \u003d business_df \\\r\n    .filter(business_df.categories.like(\"%Restaurants%\")) \\\r\n    .join(review_df, business_df.business_id \u003d\u003d review_df.rev_business_id) \\\r\n    .selectExpr(\r\n        \"CASE \" +\r\n        \"  WHEN categories LIKE \u0027%American%\u0027 THEN \u0027American\u0027 \" +\r\n        \"  WHEN categories LIKE \u0027%Mexican%\u0027 THEN \u0027Mexican\u0027 \" +\r\n        \"  WHEN categories LIKE \u0027%Chinese%\u0027 THEN \u0027Chinese\u0027 \" +\r\n        \"  ELSE \u0027Other\u0027 \" +\r\n        \"END AS cuisine_type\",\r\n        \"rev_stars\"\r\n    ) \\\r\n    .groupBy(\"cuisine_type\") \\\r\n    .avg(\"rev_stars\") \\\r\n    .withColumnRenamed(\"avg(rev_stars)\", \"average_rating\") \\\r\n    .withColumnRenamed(\"cuisine_type\", \"Cuisine Type\") \\\r\n    .withColumnRenamed(\"average_rating\", \"Average Rating\") \\\r\n    .orderBy(\"Average Rating\", ascending\u003dFalse)\r\n\r\nz.show(result)\r\n\r\n"
    }
  ]
}