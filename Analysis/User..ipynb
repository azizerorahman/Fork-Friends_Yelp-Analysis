{
  "metadata": {
    "name": "User",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "1. Analyze the number of users joining each year."
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nfrom pyspark.sql import HiveContext\r\nfrom pyspark.sql.functions import year, to_date, col, count\r\n\r\nhc \u003d HiveContext(sc)\r\n\r\nusers_df \u003d hc.table(\u0027users\u0027)\r\n\r\nresult \u003d users_df.withColumn(\"join_year\", year(col(\"user_yelping_since\"))) \\\r\n                .groupBy(\"join_year\") \\\r\n                .agg(count(\"*\").alias(\"users\")) \\\r\n                .orderBy(\"join_year\") \\\r\n                .withColumnRenamed(\"join_year\", \"Joining Year\") \\\r\n                .withColumnRenamed(\"users\", \"Users\")\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "2. Identify top reviewers based on review_count."
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\n%pyspark\nfrom pyspark.sql import HiveContext\nfrom pyspark.sql.functions import desc\n\nhc \u003d HiveContext(sc)\n\nusers_df \u003d hc.table(\u0027users\u0027)\n\nresult \u003d users_df.select(\"user_name\", \"user_review_count\") \\\n                .orderBy(desc(\"user_review_count\")) \\\n                .withColumnRenamed(\"user_name\", \"User Name\") \\\n                .withColumnRenamed(\"user_review_count\", \"Review Count\")\n\nz.show(result)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "3. Identify the most popular users based on fans."
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\n%pyspark\nfrom pyspark.sql import HiveContext\nfrom pyspark.sql.functions import desc\n\nhc \u003d HiveContext(sc)\nusers_df \u003d hc.table(\u0027users\u0027)\n\nresult \u003d users_df.select(\"user_name\", \"user_fans\") \\\n                .orderBy(desc(\"user_fans\")) \\\n                .withColumnRenamed(\"user_name\", \"User Name\") \\\n                .withColumnRenamed(\"user_fans\", \"Fan Count\")\n\nz.show(result)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "4. Calculate the ratio of elite users to regular users each year."
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nfrom pyspark.sql import HiveContext\r\nfrom pyspark.sql.functions import year, col, count, when\r\n\r\nhc \u003d HiveContext(sc)\r\n\r\nusers_df \u003d hc.table(\u0027users\u0027)\r\n\r\nusers_with_year \u003d users_df.withColumn(\"join_year\", year(col(\"user_yelping_since\")))\r\n\r\nusers_with_year \u003d users_with_year.withColumn(\"is_elite\", when(col(\"user_elite\") !\u003d \"\", 1).otherwise(0))\r\n\r\nresult \u003d users_with_year.groupBy(\"join_year\") \\\r\n                        .agg(count(when(col(\"is_elite\") \u003d\u003d 1, 1)).alias(\"elite_users\"),\r\n                             count(when(col(\"is_elite\") \u003d\u003d 0, 1)).alias(\"regular_users\")) \\\r\n                        .withColumn(\"elite_to_regular_ratio\", \r\n                                    (col(\"elite_users\") / col(\"regular_users\"))) \\\r\n                        .orderBy(\"join_year\")\r\n\r\nresult \u003d result.withColumnRenamed(\"join_year\", \"Joining Year\") \\\r\n               .withColumnRenamed(\"elite_users\", \"Elite Users\") \\\r\n               .withColumnRenamed(\"regular_users\", \"Regular Users\") \\\r\n               .withColumnRenamed(\"elite_to_regular_ratio\", \"Elite to Regular Ratio\")\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "5. Display the proportion of total users and silent users (users who haven\u0027t written reviews) each year."
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nfrom pyspark.sql import functions as F\r\nfrom pyspark.sql.types import StringType\r\n\r\ndf \u003d spark.table(\"users\")\r\n\r\ndf_with_year \u003d df.withColumn(\"join_year\", F.year(F.col(\"user_yelping_since\")))\r\n\r\ntotal_users \u003d df_with_year.groupBy(\"join_year\") \\\r\n                          .count() \\\r\n                          .withColumnRenamed(\"join_year\", \"Year\") \\\r\n                          .withColumnRenamed(\"count\", \"Total Users\")\r\n\r\nsilent_users \u003d df_with_year.filter(F.col(\"user_review_count\") \u003d\u003d 0) \\\r\n                           .groupBy(\"join_year\") \\\r\n                           .count() \\\r\n                           .withColumnRenamed(\"join_year\", \"Year\") \\\r\n                           .withColumnRenamed(\"count\", \"Silent Users\")\r\n\r\nresult \u003d total_users.join(silent_users, \"Year\", \"left\") \\\r\n                    .na.fill({\"Silent Users\": 0}) \\\r\n                    .withColumn(\"Proportion of Silent Users\", \r\n                                F.format_number(F.col(\"Silent Users\") / F.col(\"Total Users\"), 8)) \\\r\n                    .orderBy(\"Year\")\r\n\r\nz.show(result)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "6. Compute the yearly statistics of new users, number of reviews, elite users, tips, and check-ins."
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\r\n\r\n%pyspark\r\nfrom pyspark.sql.functions import year, to_date, split, explode, col, coalesce, lit\r\n\r\nusers_df \u003d spark.table(\"users\")\r\nreview_df \u003d spark.table(\"review\")\r\ntip_df \u003d spark.table(\"tip\")\r\ncheckin_df \u003d spark.table(\"checkin\")\r\n\r\nusers_df \u003d users_df.withColumn(\"year\", year(to_date(users_df.user_yelping_since))).filter(col(\"year\") \u003e 0)\r\nreview_df \u003d review_df.withColumn(\"year\", year(to_date(review_df.rev_date))).filter(col(\"year\") \u003e 0)\r\ntip_df \u003d tip_df.withColumn(\"year\", year(to_date(tip_df.tip_date))).filter(col(\"year\") \u003e 0)\r\n\r\ncheckin_df \u003d checkin_df.withColumn(\"checkin_date_array\", split(checkin_df.checkin_dates, \",\")) \\\r\n                       .withColumn(\"checkin_date\", explode(\"checkin_date_array\")) \\\r\n                       .withColumn(\"year\", year(to_date(\"checkin_date\"))).filter(col(\"year\") \u003e 0)\r\n\r\nnew_users_per_year \u003d users_df.groupBy(\"year\").count().withColumnRenamed(\"count\", \"new_users\")\r\nreviews_per_year \u003d review_df.groupBy(\"year\").count().withColumnRenamed(\"count\", \"number_of_reviews\")\r\nelite_users_per_year \u003d users_df.withColumn(\"elite_years\", explode(split(users_df.user_elite, \",\"))) \\\r\n                               .withColumn(\"elite_year\", year(to_date(\"elite_years\"))) \\\r\n                               .filter(col(\"elite_year\") \u003e 0) \\\r\n                               .groupBy(\"elite_year\").count().withColumnRenamed(\"count\", \"elite_users\")\r\ntips_per_year \u003d tip_df.groupBy(\"year\").count().withColumnRenamed(\"count\", \"number_of_tips\")\r\ncheckins_per_year \u003d checkin_df.groupBy(\"year\").count().withColumnRenamed(\"count\", \"number_of_checkins\")\r\n\r\nyearly_statistics \u003d new_users_per_year \\\r\n    .join(reviews_per_year, \"year\", \"outer\") \\\r\n    .join(elite_users_per_year.withColumnRenamed(\"elite_year\", \"year\"), \"year\", \"outer\") \\\r\n    .join(tips_per_year, \"year\", \"outer\") \\\r\n    .join(checkins_per_year, \"year\", \"outer\") \\\r\n    .filter(col(\"year\") \u003e 0) \\\r\n    .orderBy(\"year\")\r\n\r\nyearly_statistics \u003d yearly_statistics \\\r\n    .withColumn(\"new_users\", coalesce(col(\"new_users\"), lit(0))) \\\r\n    .withColumn(\"number_of_reviews\", coalesce(col(\"number_of_reviews\"), lit(0))) \\\r\n    .withColumn(\"elite_users\", coalesce(col(\"elite_users\"), lit(0))) \\\r\n    .withColumn(\"number_of_tips\", coalesce(col(\"number_of_tips\"), lit(0))) \\\r\n    .withColumn(\"number_of_checkins\", coalesce(col(\"number_of_checkins\"), lit(0)))\r\n\r\nyearly_statistics \u003d yearly_statistics \\\r\n    .withColumnRenamed(\"year\", \"Year\") \\\r\n    .withColumnRenamed(\"new_users\", \"New Users\") \\\r\n    .withColumnRenamed(\"number_of_reviews\", \"Number of Reviews\") \\\r\n    .withColumnRenamed(\"elite_users\", \"Elite Users\") \\\r\n    .withColumnRenamed(\"number_of_tips\", \"Number of Tips\") \\\r\n    .withColumnRenamed(\"number_of_checkins\", \"Number of Checkins\")\r\n\r\nz.show(yearly_statistics)\r\n\r\n"
    }
  ]
}